{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns removed successfully. Cleaned dataset saved at: C:\\Users\\hibah\\Desktop\\adv stats\\cleaned_dataset1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset using the given file path\n",
    "file_path = r\"C:\\Users\\hibah\\Desktop\\adv stats\\dataset1.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Specify the columns to remove\n",
    "columns_to_remove = [\n",
    "    'name', 'email', 'phone-number', 'credit_card', 'deposit_type',\n",
    "    'agent', 'company', 'days_in_waiting_list', 'customer_type',\n",
    "    'reserved_room_type', 'assigned_room_type', 'booking_changes',\n",
    "    'distribution_channel', 'meal', 'country', 'reservation_status','hotel'\n",
    "]\n",
    "\n",
    "# Remove the specified columns\n",
    "data_cleaned = data.drop(columns=columns_to_remove)\n",
    "\n",
    "# Save the cleaned dataset to a new file (optional)\n",
    "cleaned_file_path = r\"C:\\Users\\hibah\\Desktop\\adv stats\\cleaned_dataset1.csv\"\n",
    "data_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(\"Columns removed successfully. Cleaned dataset saved at:\", cleaned_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns removed successfully. Cleaned dataset saved at: C:\\Users\\hibah\\Desktop\\adv stats\\cleaned_dataset2.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset2 from the given file path\n",
    "file_path = r\"C:\\Users\\hibah\\Desktop\\adv stats\\dataset2.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Specify the columns to remove\n",
    "columns_to_remove = ['Booking_ID', 'type_of_meal_plan', 'room_type_reserved']\n",
    "\n",
    "# Remove the specified columns\n",
    "data_cleaned = data.drop(columns=columns_to_remove)\n",
    "\n",
    "# Save the cleaned dataset to a new file\n",
    "cleaned_file_path = r\"C:\\Users\\hibah\\Desktop\\adv stats\\cleaned_dataset2.csv\"\n",
    "data_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(\"Columns removed successfully. Cleaned dataset saved at:\", cleaned_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hibah\\AppData\\Local\\Temp\\ipykernel_8440\\256205835.py:49: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data2['reservation_status_date'] = pd.to_datetime(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets merged successfully. Merged dataset saved at: C:\\Users\\hibah\\Desktop\\adv stats\\merged_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# File paths for the datasets\n",
    "file_path1 = r\"C:\\Users\\hibah\\Desktop\\adv stats\\cleaned_dataset1.csv\"\n",
    "file_path2 = r\"C:\\Users\\hibah\\Desktop\\adv stats\\cleaned_dataset2.csv\"\n",
    "\n",
    "# Load the datasets\n",
    "data1 = pd.read_csv(file_path1)\n",
    "data2_original = pd.read_csv(file_path2)\n",
    "\n",
    "# Create a new DataFrame from data2 without modifying it in place\n",
    "data2 = data2_original.copy()\n",
    "\n",
    "# Convert 'is_canceled' and 'booking_status' to binary (0 and 1)\n",
    "# For dataset1: Map 'Not_Canceled' to 0 and 'Canceled' to 1\n",
    "data1['is_canceled'] = data1['is_canceled'].map({'0': 0, '1': 1}).fillna(0).astype(int)\n",
    "\n",
    "# For dataset2: If 'booking_status' is 'Not_Canceled' map it to 0, 'Canceled' to 1\n",
    "data2['is_canceled'] = data2['booking_status'].map({'Not_Canceled': 0, 'Canceled': 1}).fillna(0).astype(int)\n",
    "\n",
    "# Rename columns in dataset2 to match dataset1 for consistency\n",
    "data2 = data2.rename(columns={\n",
    "    'no_of_adults': 'adults',\n",
    "    'no_of_children': 'children',\n",
    "    'no_of_weekend_nights': 'stays_in_weekend_nights',\n",
    "    'no_of_week_nights': 'stays_in_week_nights',\n",
    "    'market_segment_type': 'market_segment',\n",
    "    'repeated_guest': 'is_repeated_guest',\n",
    "    'no_of_previous_cancellations': 'previous_cancellations',\n",
    "    'no_of_previous_bookings_not_canceled': 'previous_bookings_not_canceled',\n",
    "    'avg_price_per_room': 'adr',\n",
    "    'required_car_parking_space': 'required_car_parking_spaces',\n",
    "    'no_of_special_requests': 'total_of_special_requests',\n",
    "    'arrival_year': 'arrival_date_year',\n",
    "    'arrival_month': 'arrival_date_month',\n",
    "    'arrival_date': 'arrival_date_day_of_month'\n",
    "})\n",
    "\n",
    "# Extract 'arrival_date_day_of_month' from 'reservation_status_date' in dataset1\n",
    "data1['arrival_date_day_of_month'] = pd.to_datetime(data1['reservation_status_date'], format='%d-%m-%Y').dt.day\n",
    "\n",
    "# Handling missing or invalid date columns in dataset2 before creating 'reservation_status_date'\n",
    "data2['arrival_date_year'] = data2['arrival_date_year'].fillna(0).astype(int)\n",
    "data2['arrival_date_month'] = data2['arrival_date_month'].fillna(0).astype(int)\n",
    "data2['arrival_date_day_of_month'] = data2['arrival_date_day_of_month'].fillna(1).astype(int)\n",
    "\n",
    "# Create 'reservation_status_date' for dataset2 using 'arrival_year', 'arrival_month', and 'arrival_date_day_of_month'\n",
    "data2['reservation_status_date'] = pd.to_datetime(\n",
    "    data2[['arrival_date_year', 'arrival_date_month', 'arrival_date_day_of_month']].astype(str).agg('-'.join, axis=1),\n",
    "    errors='coerce', dayfirst=True\n",
    ")\n",
    "\n",
    "# Add 'day_of_week' column for both datasets\n",
    "data1['day_of_week'] = pd.to_datetime(data1['reservation_status_date'], format='%d-%m-%Y').dt.day_name()\n",
    "data2['day_of_week'] = data2['reservation_status_date'].dt.day_name()\n",
    "\n",
    "# Add 'total_guests' column for both datasets\n",
    "data1['total_guests'] = data1['adults'] + data1['children'] + data1.get('babies', 0)\n",
    "data2['total_guests'] = data2['adults'] + data2['children']\n",
    "\n",
    "# Merge both datasets into a new DataFrame\n",
    "merged_data = pd.concat([data1, data2], ignore_index=True)\n",
    "\n",
    "# Drop the 'booking_status' column from the merged DataFrame\n",
    "if 'booking_status' in merged_data.columns:\n",
    "    merged_data = merged_data.drop(columns=['booking_status'])\n",
    "\n",
    "# Save the merged dataset to a new file\n",
    "merged_file_path = r\"C:\\Users\\hibah\\Desktop\\adv stats\\merged_dataset.csv\"\n",
    "merged_data.to_csv(merged_file_path, index=False)\n",
    "\n",
    "print(\"Datasets merged successfully. Merged dataset saved at:\", merged_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
